{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ongoing implementation of ExportXML importer (discoursegraphs branch: exportxml)\n",
    "\n",
    "* initially, I was working on Tueba/D-Z 5.0, but now I have version 8.0 available\n",
    "* the whole corpus is available as a single XML file, which would result in a graph  \n",
    "  that is way to large for networkx (ca. 1.7 million edges)\n",
    "  \n",
    "## Tueba-D/Z 5.0\n",
    "\n",
    "* I assumed that the corpus could not be split into documents and therefore wrote  \n",
    "  a parser using igraph instead of networkx\n",
    "* it turns out that each sentence has a ``origin`` attribute, e.g. ``T990507.2``,  \n",
    "  which translates into (collection ID: T990507, document id: 2)\n",
    "* all documents within a collection (NB: I will use those terms, Tueba doesn't)  \n",
    "  have consequtively numbered token node IDs, i.e. if document 1 contains sentences  \n",
    "  1 to 12, document 2 might contain sentences 13 to 43\n",
    "  \n",
    "## Tueba-D/Z 8.0\n",
    "\n",
    "* ``tuebadz-8.0-mit-NE+Anaphern+Diskurs.exml.xml`` contains bad XML\n",
    "\n",
    "```python\n",
    "XMLSyntaxError: ID text_145 already defined, line 4663422, column 20\n",
    "```\n",
    "\n",
    "* two text IDs occur twice: ``text_3160`` and ``text_145``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from lxml import etree, html\n",
    "import igraph as ig\n",
    "\n",
    "import discoursegraphs as dg\n",
    "\n",
    "TUEBADZ5_FILE = os.path.expanduser(\n",
    "    '~/corpora/tueba/tuebadz-5.0/data/XML/tuebadz-5.0.anaphora.export.xml')\n",
    "\n",
    "TUEBADZ8_FILE = os.path.expanduser(\n",
    "    '~/corpora/tueba/TuebaDZ8.0/tuebadz-8.0-mit-NE+Anaphern+Diskurs.exml.xml')\n",
    "\n",
    "HTML_PARSER = html.HTMLParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ns(key, ns='http://www.w3.org/XML/1998/namespace'):\n",
    "    \"\"\"\n",
    "    adds a namespace prefix to a string, e.g. turns 'foo' into\n",
    "    '{http://www.w3.org/XML/1998/namespace}foo'\n",
    "    \"\"\"\n",
    "    return '{{{namespace}}}{key}'.format(namespace=ns, key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# represent the whole corpus in an iterable (over documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "class ExportXMLCorpus(object):\n",
    "    def __init__(self, exportxml_file, parse=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        exportxml_file : str\n",
    "            path to an ExportXML formatted corpus file\n",
    "        parse : bool\n",
    "            If True, create an iterator that parses the documents\n",
    "            contained in the file into ExportXMLDocumentGraph instances.\n",
    "            Otherwise, yield the etree element representations of the <text>\n",
    "            elements found in the document.\n",
    "        \"\"\"\n",
    "        self.parse = parse\n",
    "        self.__context = etree.iterparse(exportxml_file, events=('end',), tag='text', recover=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.text_iter(self.__context))\n",
    "\n",
    "    def next(self):\n",
    "        # to build an iterable, __iter__() would be sufficient,\n",
    "        # but adding a next() method is quite common\n",
    "        return self.__iter__().next()\n",
    "        \n",
    "    def text_iter(self, context):\n",
    "        \"\"\"\n",
    "        iterates over all the elements in an iterparse context (here: <text> elements)\n",
    "        and yields an ExportXMLDocumentGraph instance for each of them.\n",
    "        afterwards, the elements are removed from the DOM / main memory.\n",
    "        \"\"\"\n",
    "        for _event, elem in context:\n",
    "            if self.parse:\n",
    "                yield ExportXMLDocumentGraph(elem)\n",
    "            else:\n",
    "                yield elem\n",
    "            # removes element (and references to it) from memory after processing it\n",
    "            elem.clear()\n",
    "            while elem.getprevious() is not None:\n",
    "                del elem.getparent()[0]\n",
    "        del context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pudb # TODO: remove after debugging\n",
    "\n",
    "import discoursegraphs as dg\n",
    "from discoursegraphs import DiscourseDocumentGraph\n",
    "\n",
    "\n",
    "class ExportXMLDocumentGraph(DiscourseDocumentGraph):\n",
    "    \"\"\"\n",
    "    represents an ExportXML document as a document graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, text_element, name=None, namespace='exportxml',\n",
    "                 precedence=False):\n",
    "        \"\"\"\n",
    "        creates a document graph from a <text> element from an ExportXML file.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text_element : lxml.etree._Element\n",
    "            a <text> element from an ExportXML file parsed with lxml\n",
    "        name : str or None\n",
    "            the name or ID of the graph to be generated. If no name is\n",
    "            given, the xml:id of the <text> element is used\n",
    "        namespace : str\n",
    "            the namespace of the document (default: exportxml)\n",
    "        precedence : bool\n",
    "            If True, add precedence relation edges\n",
    "            (root precedes token1, which precedes token2 etc.)\n",
    "        \"\"\"\n",
    "        # super calls __init__() of base class DiscourseDocumentGraph\n",
    "        super(ExportXMLDocumentGraph, self).__init__()\n",
    "        \n",
    "        self.name = name if name else text_element.attrib[add_ns('id')]\n",
    "        self.ns = namespace\n",
    "        self.root = self.ns+':root_node'\n",
    "        self.add_node(self.root, layers={self.ns}, label=self.ns+':root_node')\n",
    "\n",
    "        self.sentences = []\n",
    "        self.tokens = []\n",
    "        \n",
    "        self.parsers = {\n",
    "            'connective': self.add_connective,\n",
    "            'discRel': self.add_discrel,\n",
    "            'edu': self.add_edu,\n",
    "            'edu-range': self.add_edurange,\n",
    "            'ne': self.add_ne,\n",
    "            'node': self.add_node_element, # add_node() is already present in graph class\n",
    "            'relation': self.add_relation,\n",
    "            'secEdge': self.add_secedge,\n",
    "            'sentence': self.add_sentence,\n",
    "            'splitRelation': self.add_splitrelation,\n",
    "            'topic': self.add_topic,\n",
    "            'word': self.add_word\n",
    "        }\n",
    "        \n",
    "        self.parse_descedant_elements(text_element)\n",
    "\n",
    "    def parse_child_elements(self, element):\n",
    "        '''parses all children of an etree element'''\n",
    "        for child in element.iterchildren():\n",
    "            self.parsers[child.tag](child)\n",
    "\n",
    "    def parse_descedant_elements(self, element):\n",
    "        '''parses all descendants of an etree element'''\n",
    "        for descendant in element.iterdescendants():\n",
    "            self.parsers[descendant.tag](descendant)\n",
    "  \n",
    "    def add_connective(self, connective):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        connective : etree.Element\n",
    "            etree representation of a <connective> element\n",
    "            (annotates connective tokens)\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "          <word xml:id=\"s29_1\" form=\"Als\" pos=\"KOUS\" lemma=\"als\" func=\"-\"\n",
    "                parent=\"s29_500\" dephead=\"s29_14\" deprel=\"KONJ\">\n",
    "              <connective konn=\"als\" rel1=\"Temporal\" rel2=\"enable\"/>\n",
    "          </word>\n",
    "        \"\"\"\n",
    "        word_node_id = self.get_element_id(connective)\n",
    "        # add a key 'connective' to the token with add rel1/rel2 attributes as a dict and\n",
    "        # add the token to the namespace:connective layer\n",
    "        connective_attribs = {key: val for (key, val) in connective.attrib.items() if key != 'konn'}\n",
    "        word_node = self.node[word_node_id]\n",
    "        word_node['layers'].add(self.ns+':connective')\n",
    "        word_node.update({'connective': connective_attribs})\n",
    "            \n",
    "    def add_discrel(self, discrel):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        add_discrel : etree.Element\n",
    "            etree representation of a <discRel> element\n",
    "            Describes the relation between two EDUs.\n",
    "            The ID of the other EDU is given in the arg2 attribute.\n",
    "            Note, that arg2 can either reference an EDU (e.g. edu_9_3_2\n",
    "            or an EDU range, e.g. edus9_3_1-5_0).\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "\n",
    "           <edu xml:id=\"edu_9_3_0\">\n",
    "            <discRel relation=\"Explanation-Speechact\" marking=\"-\" arg2=\"edus9_3_1-5_0\"/>\n",
    "            <node xml:id=\"s128_504\" cat=\"SIMPX\" func=\"--\">\n",
    "            ...\n",
    "            </node>\n",
    "            <word xml:id=\"s128_3\" form=\":\" pos=\"$.\" lemma=\":\" func=\"--\" deprel=\"ROOT\"/>\n",
    "           </edu>\n",
    "\n",
    "             <edu xml:id=\"edu_9_3_1\">\n",
    "              <discRel relation=\"Continuation\" marking=\"-\" arg2=\"edu_9_3_2\"/>\n",
    "              <node xml:id=\"s128_506\" cat=\"VF\" func=\"-\" parent=\"s128_525\">\n",
    "              ...\n",
    "              </node>\n",
    "              ...\n",
    "             </edu>\n",
    "        \"\"\"\n",
    "        arg1_id = self.get_element_id(discrel)\n",
    "        arg2_id = discrel.attrib['arg2']\n",
    "        reltype = discrel.attrib['relation']\n",
    "        discrel_attribs = self.element_attribs_to_dict(discrel)\n",
    "        self.node[arg1_id].update(discrel_attribs)\n",
    "        self.add_layer(arg1_id, self.ns+':discourse')\n",
    "        self.add_layer(arg1_id, self.ns+':relation')\n",
    "        self.add_edge(arg1_id, arg2_id,\n",
    "                      layers={self.ns, self.ns+':discourse', self.ns+':relation'},\n",
    "                      edge_type=dg.EdgeTypes.pointing_relation,\n",
    "                      relation=reltype,\n",
    "                      label='discourse:'+reltype)\n",
    "\n",
    "    def add_edu(self, edu):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        edu : etree.Element\n",
    "            etree representation of a <edu> element\n",
    "            (annotates an EDU)\n",
    "            Note: the arg1 EDU has a discRel child, the arg2 doesn't\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        <edu xml:id=\"edu_55_21_1\">\n",
    "         <discRel relation=\"Explanation-Cause\" marking=\"-|*um zu\" arg2=\"edu_55_21_2\"/>\n",
    "         <word xml:id=\"s905_9\" form=\"und\" pos=\"KON\" lemma=\"und\" func=\"-\" parent=\"s905_526\" dephead=\"s905_3\" deprel=\"KON\"/>\n",
    "         <node xml:id=\"s905_525\" cat=\"FKONJ\" func=\"KONJ\" parent=\"s905_526\" span=\"s905_10..s905_19\">\n",
    "\n",
    "        ...\n",
    "\n",
    "       <edu xml:id=\"edu_55_21_2\" span=\"s905_14..s905_20\">\n",
    "        <node xml:id=\"s905_524\" cat=\"NF\" func=\"-\" parent=\"s905_525\">\n",
    "        \"\"\"\n",
    "        edu_id = self.get_element_id(edu)\n",
    "        edu_attribs = self.element_attribs_to_dict(edu) # contains 'span' or nothing\n",
    "        self.add_node(edu_id, layers={self.ns, self.ns+':edu'}, attr_dict=edu_attribs)\n",
    "        \n",
    "        edu_token_ids = []\n",
    "        for word in edu.iterdescendants('word'):\n",
    "            word_id = self.get_element_id(word)\n",
    "            edu_token_ids.append(word_id)\n",
    "            self.add_edge(edu_id, word_id, layers={self.ns, self.ns+':edu'},\n",
    "                          edge_type=dg.EdgeTypes.spanning_relation)\n",
    "        \n",
    "        self.node[edu_id]['tokens'] = edu_token_ids\n",
    "    \n",
    "    def add_edurange(self, edurange):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        edurange : etree.Element\n",
    "            etree representation of a <edurange> element\n",
    "            (annotation that groups a number of EDUs)            \n",
    "            <edu-range> seems to glue together a number of `<edu> elements,\n",
    "            which may be scattered over a number of sentences\n",
    "            <edu-range> may or may not contain a span attribute\n",
    "            (it seems that the span attribute is present, when <edu-range> is\n",
    "            a descendent of <sentence>)\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "    \n",
    "           <edu-range xml:id=\"edus9_3_1-5_0\" span=\"s128_4..s130_7\">\n",
    "            <node xml:id=\"s128_525\" cat=\"SIMPX\" func=\"--\">\n",
    "             <edu xml:id=\"edu_9_3_1\">\n",
    "              <discRel relation=\"Continuation\" marking=\"-\" arg2=\"edu_9_3_2\"/>\n",
    "              <node xml:id=\"s128_506\" cat=\"VF\" func=\"-\" parent=\"s128_525\">\n",
    "               <node xml:id=\"s128_505\" cat=\"NX\" func=\"ON\" parent=\"s128_506\">\n",
    "                <relation type=\"expletive\"/>\n",
    "                <word xml:id=\"s128_4\" form=\"Es\" pos=\"PPER\" morph=\"nsn3\" lemma=\"es\" func=\"HD\" parent=\"s128_505\" dephead=\"s128_5\" deprel=\"SUBJ\"/>\n",
    "               </node>\n",
    "              </node>\n",
    "\n",
    "            ...\n",
    "\n",
    "          <edu-range xml:id=\"edus37_8_0-8_1\">\n",
    "           <discRel relation=\"Restatement\" marking=\"-\" arg2=\"edu_37_9_0\"/>\n",
    "           <sentence xml:id=\"s660\">\n",
    "        \"\"\"\n",
    "        edurange_id = self.get_element_id(edurange)\n",
    "        edurange_attribs = self.element_attribs_to_dict(edurange) # contains 'span' or nothing\n",
    "        self.add_node(edurange_id, layers={self.ns, self.ns+':edu:range'}, attr_dict=edurange_attribs)\n",
    "        for edu in edurange.iterdescendants('edu'):\n",
    "            edu_id = self.get_element_id(edu)\n",
    "            self.add_edge(edurange_id, edu_id, layers={self.ns, self.ns+':edu:range'},\n",
    "                          edge_type=dg.EdgeTypes.spanning_relation)\n",
    "\n",
    "    def add_ne(self, ne):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ne : etree.Element\n",
    "            etree representation of a <ne> element\n",
    "            (marks a text span -- (one or more <node> or <word> elements) as a named entity)\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "            <ne xml:id=\"ne_23\" type=\"PER\">\n",
    "             <word xml:id=\"s3_2\" form=\"Ute\" pos=\"NE\" morph=\"nsf\" lemma=\"Ute\" func=\"-\" parent=\"s3_501\" dephead=\"s3_1\" deprel=\"APP\"/>\n",
    "             <word xml:id=\"s3_3\" form=\"Wedemeier\" pos=\"NE\" morph=\"nsf\" lemma=\"Wedemeier\" func=\"-\" parent=\"s3_501\" dephead=\"s3_2\" deprel=\"APP\"/>\n",
    "            </ne>\n",
    "        \"\"\"\n",
    "        ne_id = self.get_element_id(ne)\n",
    "        ne_label = 'ne:'+ne.attrib['type']\n",
    "        self.add_node(ne_id, layers={self.ns, self.ns+':ne'},\n",
    "                      attr_dict=self.element_attribs_to_dict(ne),\n",
    "                      label=ne_label)\n",
    "        # possible children: [('word', 78703), ('node', 11152), ('ne', 49)]\n",
    "        for child in ne.iterchildren():\n",
    "            child_id = self.get_element_id(child)\n",
    "            self.add_edge(ne_id, child_id, layers={self.ns, self.ns+':ne'},\n",
    "                          edge_type=dg.EdgeTypes.spanning_relation,\n",
    "                          label=ne_label)\n",
    "\n",
    "    def add_node_element(self, node):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : etree.Element\n",
    "            etree representation of a <node> element\n",
    "            A <node> describes an element of a syntax tree.\n",
    "            The root <node> element does not have a parent attribute,\n",
    "            while non-root nodes do\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        <node xml:id=\"s1_505\" cat=\"SIMPX\" func=\"--\">\n",
    "            <node xml:id=\"s1_501\" cat=\"LK\" func=\"-\" parent=\"s1_505\">\n",
    "            \n",
    "            # this is the root of the syntax tree of the sentence, but\n",
    "            # it is not the root node of the sentence, since there might\n",
    "            # be nodes outside of the tree which are children of the\n",
    "            # sentence root node (e.g. <word> elements representing a\n",
    "            # quotation mark)\n",
    "\n",
    "        \"\"\"\n",
    "        node_id = self.get_element_id(node)\n",
    "        if 'parent' in node.attrib:\n",
    "            parent_id = self.get_parent_id(node)\n",
    "        else:\n",
    "            # <node> is the root of the syntax tree of a sentence,\n",
    "            # but it might be embedded in a <edu> or <edu-range>.\n",
    "            # we want to attach it directly to the <sentence> element\n",
    "            parent_id = self.get_sentence_id(node)\n",
    "        self.add_node(node_id, layers={self.ns, self.ns+':syntax'},\n",
    "                      attr_dict=self.element_attribs_to_dict(node),\n",
    "                      label=node.attrib['cat'])\n",
    "        self.add_edge(parent_id, node_id, edge_type=dg.EdgeTypes.dominance_relation)\n",
    "\n",
    "    def add_relation(self, relation):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        relation : etree.Element\n",
    "            etree representation of a <relation> element\n",
    "            A <relation> always has a type attribute and inherits\n",
    "            its ID from its parent element. In the case of a non-expletive\n",
    "            relation, it also has a target attribute.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "          <node xml:id=\"s29_501\" cat=\"NX\" func=\"ON\" parent=\"s29_523\">\n",
    "           <relation type=\"expletive\"/>\n",
    "           <word xml:id=\"s29_2\" form=\"es\" pos=\"PPER\" morph=\"nsn3\" lemma=\"es\"\n",
    "                 func=\"HD\" parent=\"s29_501\" dephead=\"s29_14\" deprel=\"SUBJ\"/>\n",
    "          </node>\n",
    "\n",
    "          ...\n",
    "\n",
    "         <node xml:id=\"s4_507\" cat=\"NX\" func=\"ON\" parent=\"s4_513\">\n",
    "          <relation type=\"coreferential\" target=\"s1_502\"/>\n",
    "          <node xml:id=\"s4_505\" cat=\"NX\" func=\"HD\" parent=\"s4_507\">\n",
    "          ...\n",
    "          </node>\n",
    "         </node>\n",
    "        \"\"\"\n",
    "        parent_node_id = self.get_parent_id(relation)\n",
    "        reltype = relation.attrib['type']\n",
    "        # add relation type information to parent node\n",
    "        self.node[parent_node_id].update({'relation': reltype})\n",
    "        if 'target' in relation.attrib:\n",
    "            self.add_edge(parent_node_id, relation.attrib['target'],\n",
    "                          layers={self.ns, self.ns+':'+reltype,\n",
    "                                  self.ns+':coreference'},\n",
    "                          label=reltype,\n",
    "                          edge_type=dg.EdgeTypes.pointing_relation)\n",
    "\n",
    "    def add_secedge(self, secedge):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        secedge : etree.Element\n",
    "            etree representation of a <secedge> element\n",
    "        A <secEdge> element has a cat and a parent attribute,\n",
    "        but inherits its ID from its parent element.\n",
    "        It describes a secondary edge in a tree-like syntax representation.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "           <node xml:id=\"s10_505\" cat=\"VXINF\" func=\"OV\" parent=\"s10_507\">\n",
    "            <secEdge cat=\"refvc\" parent=\"s10_504\"/>\n",
    "            <word xml:id=\"s10_6\" form=\"worden\" pos=\"VAPP\" lemma=\"werden%passiv\" func=\"HD\" parent=\"s10_505\" dephead=\"s10_7\" deprel=\"AUX\"/>\n",
    "           </node>\n",
    "        \"\"\"\n",
    "        edge_source = self.get_parent_id(secedge)\n",
    "        edge_target = self.get_element_id(secedge)\n",
    "        self.add_edge(edge_source, edge_target,\n",
    "                      layers={self.ns, self.ns+':secedge'},\n",
    "                      label='secedge:'+secedge.attrib['cat'],\n",
    "                      edge_type=dg.EdgeTypes.pointing_relation)\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : etree.Element\n",
    "            etree representation of a sentence\n",
    "            (syntax tree with coreference annotation)\n",
    "        \"\"\"\n",
    "        sent_root_id = sentence.attrib[add_ns('id')]\n",
    "        # add edge from document root to sentence root\n",
    "        self.add_edge(self.root, sent_root_id, edge_type=dg.EdgeTypes.spanning_relation)\n",
    "        self.sentences.append(sent_root_id)\n",
    "\n",
    "        sentence_token_ids = []\n",
    "        \n",
    "        for descendant in sentence.iterdescendants('word'):\n",
    "            sentence_token_ids.append(self.get_element_id(descendant))\n",
    "        \n",
    "        self.node[sent_root_id]['tokens'] = sentence_token_ids\n",
    "\n",
    "    def add_splitrelation(self, splitrelation):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        splitrelation : etree.Element\n",
    "            etree representation of a <splitRelation> element\n",
    "            A <splitRelation> annotates its parent element (e.g. as an anaphora).\n",
    "            Its parent can be either a <word> or a <node>.\n",
    "            A <splitRelation> has a target attribute, which describes\n",
    "            the targets (plural! e.g. antecedents) of the relation.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "            <node xml:id=\"s2527_528\" cat=\"NX\" func=\"-\" parent=\"s2527_529\">\n",
    "             <splitRelation type=\"split_antecedent\" target=\"s2527_504 s2527_521\"/>\n",
    "             <word xml:id=\"s2527_32\" form=\"beider\" pos=\"PIDAT\" morph=\"gpf\" lemma=\"beide\" func=\"-\" parent=\"s2527_528\" dephead=\"s2527_33\" deprel=\"DET\"/>\n",
    "             <word xml:id=\"s2527_33\" form=\"Firmen\" pos=\"NN\" morph=\"gpf\" lemma=\"Firma\" func=\"HD\" parent=\"s2527_528\" dephead=\"s2527_31\" deprel=\"GMOD\"/>\n",
    "            </node>\n",
    "\n",
    "            <word xml:id=\"s3456_12\" form=\"ihr\" pos=\"PPOSAT\" morph=\"nsm\" lemma=\"ihr\" func=\"-\" parent=\"s3456_507\" dephead=\"s3456_14\" deprel=\"DET\">\n",
    "             <splitRelation type=\"split_antecedent\" target=\"s3456_505 s3456_9\"/>\n",
    "            </word>\n",
    "        \"\"\"\n",
    "        source_id = self.get_element_id(splitrelation)\n",
    "        # the target attribute looks like this: target=\"s2527_504 s2527_521\"\n",
    "        target_node_ids = splitrelation.attrib['target'].split()\n",
    "        # we'll create an additional node which spans all target nodes\n",
    "        target_span_id = '__'.join(target_node_ids)\n",
    "        reltype = splitrelation.attrib['type']\n",
    "        self.add_node(source_id,\n",
    "                      layers={self.ns, self.ns+':relation', self.ns+':'+reltype})\n",
    "        self.add_node(target_span_id,\n",
    "                      layers={self.ns, self.ns+':targetspan', self.ns+':'+reltype})\n",
    "        self.add_edge(source_id, target_span_id,\n",
    "                      layers={self.ns, self.ns+':coreference', self.ns+':'+reltype},\n",
    "                      edge_type=dg.EdgeTypes.pointing_relation)        \n",
    "        \n",
    "        for target_node_id in target_node_ids:\n",
    "            self.add_edge(target_span_id, target_node_id,\n",
    "                          layers={self.ns, self.ns+reltype},\n",
    "                          edge_type=dg.EdgeTypes.spanning_relation)\n",
    "\n",
    "    def add_topic(self, topic):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        topic : etree.Element\n",
    "            etree representation of a <topic> element\n",
    "            (topic annotation of a text span, e.g. a sentence, edu or edu-range)\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "            <topic xml:id=\"topic_9_0\" description=\"Kuli\">\n",
    "                <sentence xml:id=\"s128\">\n",
    "\n",
    "            ...\n",
    "\n",
    "            <topic xml:id=\"topic_37_1\" description=\"Die PlÃ¤ne der AG\">\n",
    "                <edu-range xml:id=\"edus37_8_0-8_1\">\n",
    "                    <discRel relation=\"Restatement\" marking=\"-\" arg2=\"edu_37_9_0\"/>\n",
    "                        <sentence xml:id=\"s660\">\n",
    "        \"\"\"\n",
    "        topic_id = self.get_element_id(topic)\n",
    "        self.add_node(topic_id, layers={self.ns, self.ns+':topic'},\n",
    "                      description=topic.attrib['description'])\n",
    "        topic_tokens = []\n",
    "        for word in topic.iterdescendants('word'):\n",
    "            word_id = self.get_element_id(word)\n",
    "            topic_tokens.append(word_id)\n",
    "            self.add_edge(topic_id, word_id, layers={self.ns, self.ns+':topic'},\n",
    "                          edge_type=dg.EdgeTypes.spanning_relation)\n",
    "        self.node[topic_id]['tokens'] = topic_tokens\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        word : etree.Element\n",
    "            etree representation of a <word> element\n",
    "            (i.e. a token, which might contain child elements)\n",
    "        \"\"\"\n",
    "        word_id = self.get_element_id(word)\n",
    "        if word.getparent().tag in ('node', 'sentence'):\n",
    "            parent_id = self.get_parent_id(word)\n",
    "        else:\n",
    "            # ExportXML is an inline XML format. Therefore, a <word>\n",
    "            # might be embedded in weird elements. If this is the case,\n",
    "            # attach it directly to the closest <node> or <sentence> node\n",
    "            try:\n",
    "                parent = word.iterancestors(tag=('node', 'sentence')).next()\n",
    "                parent_id = self.get_element_id(parent)\n",
    "            except StopIteration as e:\n",
    "                # there's at least one weird edge case, where a <word> is\n",
    "                # embedded like this: (text (topic (edu (word))))\n",
    "                # here, we guess the sentence ID from the\n",
    "                parent_id = self.get_element_id(word).split('_')[0]\n",
    "\n",
    "        self.tokens.append(word_id)\n",
    "        # use all attributes except for the ID\n",
    "        word_attribs = self.element_attribs_to_dict(word)\n",
    "        # add the token string under the key namespace:token\n",
    "        token_str = word_attribs['form']\n",
    "        word_attribs.update({self.ns+':token': token_str, 'label': token_str})\n",
    "        self.add_node(word_id, layers={self.ns, self.ns+':token'}, attr_dict=word_attribs)\n",
    "        self.add_edge(parent_id, word_id, edge_type=dg.EdgeTypes.dominance_relation)\n",
    "        self.parse_child_elements(word)\n",
    "\n",
    "    def element_attribs_to_dict(self, element):\n",
    "        \"\"\"\n",
    "        converts the .attrib attributes of an etree element (from ``lxml.etree._Attrib``)\n",
    "        into a dict, leaving out the xml:id attribute.\n",
    "        \"\"\"\n",
    "        return {key: val for (key, val) in element.attrib.items()\n",
    "                if key != add_ns('id')}\n",
    "    \n",
    "    def get_element_id(self, element):\n",
    "        \"\"\"\n",
    "        Returns the ID of an element (or, if the element doesn't have one:\n",
    "        the ID of its parent). Returns an error, if both elements have no ID.\n",
    "        \"\"\"\n",
    "        id_attrib_key = add_ns('id')\n",
    "        if id_attrib_key in element.attrib:\n",
    "            return element.attrib[id_attrib_key]\n",
    "        try:\n",
    "            return element.getparent().attrib[id_attrib_key]\n",
    "        except KeyError as e:\n",
    "            raise KeyError(\n",
    "                'Neither the element \"{}\" nor its parent \"{}\" '\n",
    "                'have an ID'.format(element, element.getparent()))\n",
    "    \n",
    "    def get_parent_id(self, element):\n",
    "        \"\"\"returns the ID of the parent of the given element\"\"\"\n",
    "        if 'parent' in element.attrib:\n",
    "            return element.attrib['parent']\n",
    "        else:\n",
    "            return element.getparent().attrib[add_ns('id')]\n",
    "        \n",
    "    def get_sentence_id(self, element):\n",
    "        \"\"\"returns the ID of the sentence the given element belongs to.\"\"\"\n",
    "        try:\n",
    "            sentence_elem = element.iterancestors('sentence').next()\n",
    "        except StopIteration as e:\n",
    "            warnings.warn(\"<{}> element is not a descendant of a <sentence> \"\n",
    "                          \"We'll try to extract the sentence ID from the \"\n",
    "                          \"prefix of the element ID\".format(element.tag))\n",
    "            return self.get_element_id(element).split('_')[0]\n",
    "        return self.get_element_id(sentence_elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exml_corpus = ExportXMLCorpus(TUEBADZ8_FILE, parse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for i in range(10):\n",
    "    texts.append(exml_corpus.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = texts[9]\n",
    "\n",
    "dg.write_conll(text, '/tmp/9.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text = texts[9]\n",
    "\n",
    "# for elem in dg.select_nodes_by_layer(text, 'exportxml:discourse'):\n",
    "#     print elem\n",
    "#     print text.node[elem]\n",
    "#     targets = [target for source, target in text.out_edges(elem)]\n",
    "#     for target in targets:\n",
    "#         print '\\ttarget: ', target, 'target text: ', dg.get_text(text, target)\n",
    "#     print 'span: ', dg.get_span(text, elem)\n",
    "#     print 'text: ', dg.get_text(text, elem)\n",
    "#     print '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:499: UserWarning: <node> element is not a descendant of a <sentence> We'll try to extract the sentence ID from the prefix of the element ID\n"
     ]
    }
   ],
   "source": [
    "# for exml_doc in exml_corpus:\n",
    "# #     pass\n",
    "#     dg.write_dot(exml_doc, '/tmp/{}.dot'.format(exml_doc.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %dotstr dg.print_dot(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do those ExportXML elements represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5e0c9153641a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0melements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mExportXMLCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTUEBADZ8_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mne\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_elem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdescendants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ne'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mne_child\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ca21ebe5ede0>\u001b[0m in \u001b[0;36mtext_iter\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mafterwards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m \u001b[0mare\u001b[0m \u001b[0mremoved\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDOM\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmain\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \"\"\"\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_event\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mExportXMLDocumentGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# children of <ne>\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "elements = Counter()\n",
    "\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE, parse=False):\n",
    "    for ne in text_elem.iterdescendants('ne'):\n",
    "        for ne_child in ne.iterchildren():\n",
    "            elements[ne_child.tag] += 1\n",
    "        \n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parents of <word>\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "elements = Counter()\n",
    "\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE, parse=False):\n",
    "    for word in text_elem.iterdescendants('word'):\n",
    "        elements[word.getparent().tag] += 1\n",
    "        \n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# internal structure of non-<sentence> children of <text>\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "elements = defaultdict(lambda : defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE, parse=False):\n",
    "    for child in text_elem.iterchildren():\n",
    "        if child.tag != 'sentence':\n",
    "            for grandchild in child.iterchildren():\n",
    "                elements[child.tag][grandchild.tag] += 1\n",
    "        \n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for child in elements:\n",
    "    print child\n",
    "    print elements[child], '\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "elements = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for descendant in text_elem.iterdescendants():\n",
    "        elements[descendant.tag] += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from operator import itemgetter\n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "[('node', 1611076),\n",
    " ('word', 1365642),\n",
    " ('relation', 109239),\n",
    " ('sentence', 75408),\n",
    " ('ne', 66564),\n",
    " ('secEdge', 5450),\n",
    " ('edu', 1612),\n",
    " ('connective', 1522),\n",
    " ('discRel', 1458),\n",
    " ('edu-range', 323),\n",
    " ('splitRelation', 297),\n",
    " ('topic', 141)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Do ``<text>`` elements only contain ``<sentence>`` as children? NO!\n",
    "\n",
    "* ``<topic>`` can occur as a parent of ``<sentence>`` and describes them\n",
    "* ``<topic>`` never occur elsewhere\n",
    "\n",
    "```xml\n",
    "...\n",
    "   <word xml:id=\"s132_21\" form=\".\" pos=\"$.\" lemma=\".\" func=\"--\" deprel=\"ROOT\"/>\n",
    "   </edu>\n",
    "  </sentence>\n",
    " </topic>\n",
    " <topic xml:id=\"topic_9_2\" description=\"Probleme bei weiblichen Alkoholismus\">\n",
    "  <sentence xml:id=\"s133\">\n",
    "   <node xml:id=\"s133_530\" cat=\"SIMPX\" func=\"--\">\n",
    "    <edu xml:id=\"edu_9_8_0\">\n",
    "...\n",
    "```\n",
    "\n",
    "* ```<edu-range>``` seems to glue together a number of ```<edu>`` elements,  \n",
    "  which may be scattered over a number of sentences\n",
    "* ```<edu-range>``` may or may not contain a ``span`` attribute\n",
    "\n",
    "```python\n",
    "   <edu-range xml:id=\"edus9_3_1-5_0\" span=\"s128_4..s130_7\">\n",
    "    <node xml:id=\"s128_525\" cat=\"SIMPX\" func=\"--\">\n",
    "     <edu xml:id=\"edu_9_3_1\">\n",
    "      <discRel relation=\"Continuation\" marking=\"-\" arg2=\"edu_9_3_2\"/>\n",
    "      <node xml:id=\"s128_506\" cat=\"VF\" func=\"-\" parent=\"s128_525\">\n",
    "       <node xml:id=\"s128_505\" cat=\"NX\" func=\"ON\" parent=\"s128_506\">\n",
    "        <relation type=\"expletive\"/>\n",
    "        <word xml:id=\"s128_4\" form=\"Es\" pos=\"PPER\" morph=\"nsn3\" lemma=\"es\" func=\"HD\" parent=\"s128_505\" dephead=\"s128_5\" deprel=\"SUBJ\"/>\n",
    "       </node>\n",
    "      </node>\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Do ``<topic>`` elements describe one or potentially more sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elements = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for child in text_elem.iterchildren():\n",
    "        elements[child.tag] += 1\n",
    "        \n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# children of <topic>\n",
    "\n",
    "elements = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for topic in text_elem.iterdescendants('topic'):\n",
    "        for child in topic.iterchildren():\n",
    "            elements[child.tag] += 1\n",
    "        \n",
    "sorted(elements.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do ``<sentence>`` elements only contain ``<node>`` as children? NO!\n",
    "\n",
    "* ``<word>, <ne>, <edu> and <edu-range>`` can be children of ``<sentence>`` as well!\n",
    "* e.g. quotation marks ``<word>`` elements occur outside of a ``<node>``\n",
    "\n",
    "```xml\n",
    " <sentence xml:id=\"s2196\">\n",
    "  <word xml:id=\"s2196_1\" form='\"' pos=\"$(\" lemma='\"' func=\"--\" deprel=\"ROOT\"/>\n",
    "  <node xml:id=\"s2196_526\" cat=\"SIMPX\" func=\"--\">\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all types of children of <sentence>\n",
    "\n",
    "sent_children = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for sentence in text_elem.iterdescendants('sentence'):\n",
    "        for child in sentence.iterchildren():\n",
    "            sent_children[child.tag] += 1\n",
    "        \n",
    "sorted(sent_children.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all types of descendants of <sentence>\n",
    "\n",
    "sent_children = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for sentence in text_elem.iterdescendants('sentence'):\n",
    "        for child in sentence.iterdescendants():\n",
    "            sent_children[child.tag] += 1\n",
    "        \n",
    "sorted(sent_children.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do ``<word>`` elements have children? YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_children = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for word in text_elem.iterdescendants('word'):\n",
    "        for child in word.iterdescendants():\n",
    "            word_children[child.tag] += 1\n",
    "\n",
    "sorted(word_children.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* when parsing ``<word>`` as tokens for a sentence, keep an eye on ``<relation>, <connective> and <splitRelation>``\n",
    "* ``<relation>`` can either occur as a daughter of ``<word>`` **OR** as a predecessor of ``<node>`` or ``<word>``\n",
    "* a ``<relation>`` always gets its ID from its parent and contains its target as an attribute\n",
    "\n",
    "```xml\n",
    "      <node xml:id=\"s149_507\" cat=\"NX\" func=\"ON\" parent=\"s149_509\">\n",
    "       <relation type=\"anaphoric\" target=\"s149_501\"/>\n",
    "       <word xml:id=\"s149_8\" form=\"sie\" pos=\"PPER\" morph=\"np*3\" lemma=\"sie\" func=\"HD\" parent=\"s149_507\" dephead=\"s149_10\" deprel=\"SUBJ\"/>\n",
    "      </node>\n",
    "```\n",
    "\n",
    "```xml\n",
    "     <node xml:id=\"s4_507\" cat=\"NX\" func=\"ON\" parent=\"s4_513\">\n",
    "      <relation type=\"coreferential\" target=\"s1_502\"/>\n",
    "      <node xml:id=\"s4_505\" cat=\"NX\" func=\"HD\" parent=\"s4_507\">\n",
    "       <word xml:id=\"s4_4\" form=\"die\" pos=\"ART\" morph=\"nsf\" lemma=\"die\" func=\"-\" parent=\"s4_505\" dephead=\"s4_5\" deprel=\"DET\"/>\n",
    "       <ne xml:id=\"ne_32\" type=\"ORG\">\n",
    "        <word xml:id=\"s4_5\" form=\"Arbeiterwohlfahrt\" pos=\"NN\" morph=\"nsf\" lemma=\"Arbeiterwohlfahrt\" func=\"HD\" parent=\"s4_505\" dephead=\"s4_3\" deprel=\"SUBJ\"/>\n",
    "       </ne>\n",
    "      </node>\n",
    "      <node xml:id=\"s4_506\" cat=\"NX\" func=\"-\" parent=\"s4_507\">\n",
    "       <ne xml:id=\"ne_33\" type=\"GPE\">\n",
    "        <word xml:id=\"s4_6\" form=\"Bremen\" pos=\"NE\" morph=\"nsn\" lemma=\"Bremen\" func=\"HD\" parent=\"s4_506\" dephead=\"s4_5\" deprel=\"APP\"/>\n",
    "       </ne>\n",
    "      </node>\n",
    "     </node>\n",
    "```\n",
    "\n",
    "```xml\n",
    "       <word xml:id=\"s4_7\" form=\"ihren\" pos=\"PPOSAT\" morph=\"asm\" lemma=\"ihr\" func=\"-\" parent=\"s4_509\" dephead=\"s4_9\" deprel=\"DET\">\n",
    "        <relation type=\"anaphoric\" target=\"s4_507\"/>\n",
    "       </word>\n",
    "```\n",
    "\n",
    "* ``<connective>`` is an annotation of a word\n",
    "\n",
    "```xml\n",
    "      <word xml:id=\"s29_1\" form=\"Als\" pos=\"KOUS\" lemma=\"als\" func=\"-\" parent=\"s29_500\" dephead=\"s29_14\" deprel=\"KONJ\">\n",
    "       <connective konn=\"als\" rel1=\"Temporal\" rel2=\"enable\"/>\n",
    "      </word>\n",
    "```\n",
    "\n",
    "* ``<splitRelation>`` can occur as a predecessor of ``<word>`` (i.e. a child of ``<node>``)   **OR**  \n",
    "  as a child of ``<word>``\n",
    "  and describes which targets (plural!) its relation has\n",
    "\n",
    "```xml\n",
    "        <node xml:id=\"s2527_528\" cat=\"NX\" func=\"-\" parent=\"s2527_529\">\n",
    "         <splitRelation type=\"split_antecedent\" target=\"s2527_504 s2527_521\"/>\n",
    "         <word xml:id=\"s2527_32\" form=\"beider\" pos=\"PIDAT\" morph=\"gpf\" lemma=\"beide\" func=\"-\" parent=\"s2527_528\" dephead=\"s2527_33\" deprel=\"DET\"/>\n",
    "         <word xml:id=\"s2527_33\" form=\"Firmen\" pos=\"NN\" morph=\"gpf\" lemma=\"Firma\" func=\"HD\" parent=\"s2527_528\" dephead=\"s2527_31\" deprel=\"GMOD\"/>\n",
    "        </node>\n",
    "```\n",
    "\n",
    "```xml\n",
    "        <word xml:id=\"s3456_12\" form=\"ihr\" pos=\"PPOSAT\" morph=\"nsm\" lemma=\"ihr\" func=\"-\" parent=\"s3456_507\" dephead=\"s3456_14\" deprel=\"DET\">\n",
    "         <splitRelation type=\"split_antecedent\" target=\"s3456_505 s3456_9\"/>\n",
    "        </word>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# are ``<connective>`` elements always children of ``<word>``? YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connective_parents = Counter()\n",
    "for text_elem in ExportXMLCorpus(TUEBADZ8_FILE):\n",
    "    for connective in text_elem.iterdescendants('connective'):\n",
    "            connective_parents[connective.getparent().tag] += 1\n",
    "\n",
    "sorted(connective_parents.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text(text_element, result_list):\n",
    "    text_str = 'ID: {}\\nOrigin: {}\\n\\n'.format(text_element.attrib[add_ns('id')], text_element.attrib['origin'])\n",
    "    for sentence in text_element.iterchildren('sentence'):\n",
    "        sent_str = u'line: {}\\n'.format(sentence.sourceline)\n",
    "        sent_str += u' '.join(word.attrib['form'] for word in sentence.iterdescendants('word'))\n",
    "        text_str += u'{}\\n'.format(sent_str)\n",
    "    result_list.append(text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "context = etree.iterparse(TUEBADZ8_FILE, events=('end',), tag='text', recover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %memit fast_iter(context, get_text, results)\n",
    "# peak memory: 330.86 MiB, increment: 249.31 MiB\n",
    "# %time fast_iter(context, get_text, results)\n",
    "# Wall time: 2min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%memit texts = list(fast_iter_yield(context, get_text, results))\n",
    "# peak memory: 330.86 MiB, increment: 249.31 MiB\n",
    "# %time fast_iter(context, get_text, results)\n",
    "# Wall time: 2min 13s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tree = etree.parse(TUEBADZ8_FILE)\n",
    "sentence_origins = Counter()\n",
    "\n",
    "sentences_iter = tree.iterfind('sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s0 = sentences_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print etree.tostring(s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExportXML ``<element>`` counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about `<relation>` and `<anaphora>`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def count_element_positions(tree, element):\n",
    "    element_positions = defaultdict(Counter)\n",
    "\n",
    "    for elem_instance in tree.iter(element):\n",
    "        element_positions['parent'][elem_instance.getparent().tag] += 1\n",
    "        for child in elem_instance.getchildren():\n",
    "            element_positions['children'][child.tag] += 1\n",
    "    return element_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_element_positions(tree, 'relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_element_positions(tree, 'anaphora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "\n",
    "for i in range(3):\n",
    "    print etree.tostring(anaphora_iter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "word_anaphora = [a for a in anaphora_iter if a.getparent().tag == 'word']\n",
    "for word_ana in word_anaphora[:3]:\n",
    "    print etree.tostring(word_ana)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unusual examples\n",
    "\n",
    "### expletive\n",
    "\n",
    "```\n",
    "~/corpora/tueba/tuebadz-5.0/data/XML $ ack-grep -A 5 s_11429_n_506 tuebadz-5.0.anaphora.export.xml\n",
    "        <node cat=\"NX\" comment=\"\" func=\"ON\" id=\"s_11429_n_506\">\n",
    "          <anaphora>\n",
    "            <relation type=\"expletive\" antecedent=\"\"/>\n",
    "          </anaphora>\n",
    "          <word comment=\"\" form=\"Es\" func=\"HD\" pos=\"PPER\" morph=\"nsn3\" id=\"s_11429_n_10\"/>\n",
    "        </node>\n",
    "```\n",
    "\n",
    "### split antecedent\n",
    "\n",
    "```\n",
    "27434-          <node cat=\"MF\" comment=\"\" func=\"-\" id=\"s_382_n_511\">\n",
    "27435-            <node cat=\"NX\" comment=\"\" func=\"ON\" id=\"s_382_n_501\">\n",
    "27436-              <anaphora>\n",
    "27437:                <relation type=\"split_antecedent\" antecedent=\"s_381_n_9,s_378_n_510\"/>\n",
    "27438-              </anaphora>\n",
    "27439-              <word comment=\"\" form=\"die\" func=\"-\" pos=\"ART\" morph=\"npm\" id=\"s_382_n_1\"/>\n",
    "27440-              <word comment=\"\" form=\"Partner\" func=\"HD\" pos=\"NN\" morph=\"npm\" id=\"s_382_n_2\"/>\n",
    "27441-            </node>\n",
    "27442-            <node cat=\"ADVX\" comment=\"\" func=\"OADVP\" id=\"s_382_n_502\">\n",
    "27443-              <word comment=\"\" form=\"miteinander\" func=\"HD\" pos=\"ADV\" morph=\"--\" id=\"s_382_n_3\"/>\n",
    "27444-            </node>\n",
    "27445-          </node>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "for anaphora in anaphora_iter:\n",
    "    # there's only one <relation> child element\n",
    "    antecedent = anaphora.getchildren()[0].attrib['antecedent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExportXML <element> meanings\n",
    "\n",
    "* `<node>`: a node in a syntax tree\n",
    "* `<word>`: a token in a sentence / syntax tree\n",
    "* `<relation>`: a child of an `<anaphora>` element; it's always a leaf node  \n",
    "   it has a `type` attrib (relation type) and an `antecedent` attrib (antecedent's node ID)  \n",
    "   NB: if an anaphora has no antecedent, (e.g. if it's an `expletive` relation) the `antecedent` attrib  \n",
    "   is an empty string!\n",
    "* `<anaphora>`: a child of a `<node>` or `<word>` element; always has one `<relation>` child;  \n",
    "  the element itself contains no information\n",
    "* `<sentence>`: a sentence / syntax tree\n",
    "\n",
    "```\n",
    " ('secedge', 4647),\n",
    " ('originDef', 2213),\n",
    " ('morphDef', 437),\n",
    " ('posDef', 56),\n",
    " ('edgeDef', 50),\n",
    " ('nodeDef', 29),\n",
    " ('editorDef', 26),\n",
    " ('secedgeDef', 7),\n",
    " ('comment', 6),\n",
    "\n",
    "\n",
    " ('posList', 1),\n",
    " ('secedgeList', 1),\n",
    " ('editorList', 1),\n",
    " ('edgeList', 1),\n",
    " ('originList', 1),\n",
    " ('format', 1),\n",
    " ('morphList', 1),\n",
    " ('nodeList', 1),\n",
    " ('export', 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_anaphora(anaphora, source_id):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    anaphora : etree.Element\n",
    "        an <anaphora> element\n",
    "    source_id : str\n",
    "        the node ID of the anaphora (points either to a <node> or a <word>)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    antecedent : str\n",
    "        node ID of the antecedent, e.g. ``s_4_n_527``\n",
    "    relation_type : str\n",
    "        anaphoric relation type, e.g. ``anaphoric`` or ``coreferential``\n",
    "    \"\"\"\n",
    "    # there's only one <relation> child element\n",
    "    relation = anaphora.getchildren()[0]\n",
    "    return relation.attrib['antecedent'], relation.attrib['type']\n",
    "    \n",
    "\n",
    "def exportxml2igraph(exportxml_file):\n",
    "    \"\"\"\n",
    "    TODO: add <node> and <word> attributes\n",
    "    \"\"\"\n",
    "    # in igraph, adding a single edge is prohibitively slow,\n",
    "    # as the whole index of the graph has to be rebuild!\n",
    "    # http://stackoverflow.com/questions/13974279/igraph-why-is-add-edge-function-so-slow-ompared-to-add-edges\n",
    "    # to speed this up, store the edges in a list & call add_edges() once!\n",
    "    edges = []\n",
    "    relations = {}\n",
    "    idocgraph = ig.Graph(directed=True)\n",
    "    \n",
    "    treeiter = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in treeiter:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        idocgraph.add_vertex(sent_root_id, label=sent_root_id)\n",
    "        \n",
    "        for element in sentence.iter('node', 'word', 'anaphora'):\n",
    "            parent_element = element.getparent()\n",
    "            # some <anaphora> are children of <word> elements\n",
    "            if parent_element.tag in ('node', 'word'):\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                idocgraph.add_vertex(element_id, label=element.attrib['cat'])\n",
    "                edges.append((parent_id, element_id))\n",
    "            elif element.tag == 'word':\n",
    "                idocgraph.add_vertex(element_id, label=element.attrib['form'])\n",
    "                edges.append((parent_id, element_id))\n",
    "\n",
    "            else: # element.tag == 'anaphora'\n",
    "                # <anaphora> doesn't have an ID, but it's tied to its parent element\n",
    "                antecedent_str, relation_type = parse_anaphora(element, parent_id)\n",
    "                if antecedent_str:\n",
    "                    # there might be more than one antecedent\n",
    "                    for antecedent_id in antecedent_str.split(','):\n",
    "                        edge = (parent_id, antecedent_id)\n",
    "                        edges.append(edge)\n",
    "                        relations[edge] = relation_type\n",
    "                else:\n",
    "                    # there's no antecedent in case of an expletive anaphoric relation\n",
    "                    relations[(parent_id, None)] = relation_type\n",
    "      \n",
    "    idocgraph.add_edges(edges)\n",
    "\n",
    "    # igraph doesn't store nodes/edge names in a dict, so a lookup would be O(n)\n",
    "    node_name2id = {node['name']: node.index for node in idocgraph.vs}\n",
    "    edge_endpoints2id = {(edge.source, edge.target): edge.index\n",
    "                         for edge in idocgraph.es}\n",
    "\n",
    "    for (source, target) in relations:\n",
    "        relation_type = relations[(source, target)]\n",
    "        if target:\n",
    "            edge_endpoints = (node_name2id[source], node_name2id[target])\n",
    "            idocgraph.es[edge_endpoints2id[edge_endpoints]]['exportxml:relation_type'] = relation_type\n",
    "#             idocgraph.es[idocgraph.get_eid(source, target)]['exportxml:relation_type'] = relation_type\n",
    "\n",
    "        else:\n",
    "            # there's no antecedent in case of an expletive anaphoric relation\n",
    "            \n",
    "            idocgraph.vs[node_name2id[source]]['exportxml:anaphora_type'] = relation_type\n",
    "#             idocgraph.vs.select(name=source)['exportxml:anaphora_type'] = relation_type\n",
    "    return idocgraph\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tuebagraph = exportxml2igraph(TUEBADZ_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuebagraph.ecount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuebagraph.vcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "foo = ig.Graph(directed=True)\n",
    "foo.add_vertices(['1','2','3','4'])\n",
    "foo.add_edges([('1', '1'), ('1', '2'), ('3', '4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for e in foo.es:\n",
    "#     print e, e.index, e.source, e.target\n",
    "foo.es[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in foo.vs:\n",
    "    print v, v.index, v['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo.vs.select(name='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(foo.es.select(_source='3', _target='4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def exportxml2dict(exportxml_file):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    \n",
    "    itree = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in itree:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        nodes.append( (sent_root_id, sent_root_id) )\n",
    "        \n",
    "        for element in sentence.iter('node', 'word'):\n",
    "            parent_element = element.getparent()\n",
    "            if parent_element.tag == 'node':\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                element_label = element.attrib['cat']\n",
    "            elif element.tag == 'word':\n",
    "                element_label = element.attrib['form']\n",
    "            else:\n",
    "                continue # for now, ignore other elements (e.g. <anaphora>)\n",
    "\n",
    "            nodes.append( (element_id, element_label) )\n",
    "            edges.append( (parent_id, element_id) )\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nodes, edges = exportxml2dict(TUEBADZ_FILE) # 6.63s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: preprocessed node/edge lists, edges batch insert (total: 12.81 s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create node/edge lists\n",
    "- add nodes one by one\n",
    "- add edges in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "\n",
    "idocgraph = ig.Graph()\n",
    "for node_id, node_label in nodes:\n",
    "    idocgraph.add_vertex(node_id, label=node_label)\n",
    "idocgraph.add_edges(edges)\n",
    "```\n",
    "\n",
    "CPU times: user 6.06 s, sys: 112 ms, total: 6.18 s\n",
    "Wall time: 6.18 s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: preprocessed node/edge lists, nodes & edges batch insert (total: 7.85 s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create node/edge lists\n",
    "- add nodes in one go (without labels)\n",
    "- add edges in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "\n",
    "idocgraph = ig.Graph()\n",
    "node_ids = (node_id for (node_id, node_label) in nodes)\n",
    "idocgraph.add_vertices(node_ids)\n",
    "idocgraph.add_edges(edges)\n",
    "```\n",
    "\n",
    "CPU times: user 1.16 s, sys: 60 ms, total: 1.22 s\n",
    "Wall time: 1.22 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exportxml2docgraph(exportxml_file):\n",
    "    edges = []\n",
    "    docgraph = dg.DiscourseDocumentGraph()\n",
    "    edge_attribs = {'layers': {docgraph.ns}} # default edge attributes\n",
    "    \n",
    "    treeiter = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in treeiter:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        docgraph.add_node(sent_root_id, label=sent_root_id)\n",
    "        \n",
    "        for element in sentence.iter('node', 'word'):\n",
    "            parent_element = element.getparent()\n",
    "            if parent_element.tag == 'node':\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                element_label = element.attrib['cat']\n",
    "            elif element.tag == 'word':\n",
    "                element_label = element.attrib['form']\n",
    "            else:\n",
    "                continue # for now, ignore other elements (e.g. <anaphora>)\n",
    "\n",
    "            docgraph.add_node(element_id, label=element_label)\n",
    "            edges.append((parent_id, element_id, edge_attribs))\n",
    "    docgraph.add_edges_from(edges)\n",
    "    return docgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
