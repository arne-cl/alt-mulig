CHAPTER 2. THE ARCHITECTURAL MODEL

2.1

Definition of an architecture

At the highest level of abstraction an architecture is “a way of thinking
about the world.” To be useful, however, we have to turn our way of
thinking about the world into a practical rulebook, and a set of procedures,
that tells us how to construct a particular system using our particular way
of looking at the world.
Our sodware architecture is characterised by descriptions of the following things:
1. A problem domain — What type of problem is the architecture designed to solve? Sodware architectures are not general purpose but
are designed for solving specific problems. No description of an architecture is complete without describing the type of problem that is
supposed to be solved using the architecture.
2. A philosophy — What is the reasoning behind the method of sodware
construction? What are the central ideas in the architecture?
3. A set of construction guidelines — How do we program a system?
We need an explicit set of construction guidelines. Our systems
will be written and maintained by teams of programmers—it is important that all the programmers, and system designers, understand
the system architecture, and its underlying philosophy. For practical
reasons this knowledge is conveniently maintained in the form of
construction guidelines. The full set of guidelines, includes sets of
programming rules, and examples, course material etc.
4. A set of pre-defined components — Design by “choosing from a set
of pre-defined components” is far easier than “design from scratch.”
The Erlang OTP libraries contain a complete set of pre-defined components (called behaviours) with which commonly used system components can be built. Some examples of these are the gen_server
behaviour which can be used to build client-server systems, or the
gen_event behaviour which can be used to build event-based pro-

2.2. PROBLEM DOMAIN

13

grams. The pre-defined components will be discussed more fully in
section 6.1.
Section 6.2.2 gives a simple example of how to program a server
using the gen_sever behaviour.
5. A way of describing things — How can we describe the interfaces
to a component? How can we describe a communication protocol
between two components in our system? How can we describe
the static and dynamic structure of our system? To answer these
questions we will introduce a number of dicerent, and specialised
notations. Some for describing program APIs, and other notations
for describing protocols, and system structure.
6. A way of configuring things — How can we start, stop, and configure, the system. How can we re-configure the system while it is in
operation?

2.2

Problem domain

Our system was originally designed for building telecoms switching systems. Telecoms switching systems have demanding requirements in terms
of reliability, fault-tolerance etc. Telecoms systems are expected to operate
“forever,” they should exhibit sod real-time behaviour, and they should behave reasonably in the presence of sodware and hardware errors. Däcker
[30], gave ten requirements for the properties of a telecoms system:
1. The system must be able to handle very large numbers of concurrent
activities.
2. Actions must be performed at a certain point in time or within a
certain time.
3. Systems may be distributed over several computers.
4. The system is used to control hardware.

14

CHAPTER 2. THE ARCHITECTURAL MODEL
5. The sodware systems are very large.
6. The system exhibits complex functionality such as, feature interaction.
7. The systems should be in continuous operation for many years.
8. Sodware maintenance (reconfiguration, etc) should be performed
without stopping the system.
9. There are stringent quality, and reliability requirements.

10. Fault tolerance both to hardware failures, and sodware errors, must
be provided.
We can motivate these requirements as follows:
• Concurrency — switching systems are inherently concurrent since in
a typical switch many tens of thousands of people may simultaneously interact with the switch. This implies that the system should
be able to eeciently handle many tens of thousands of concurrent
activities.
• Sod real-time — in a telecommunications system many operations
have to be performed within a specific time. Some of these timed
operations are strictly enforced, in the sense that if a given operation
does not succeed within a given time interval then the entire operation will be aborted. Other operations are merely monitored with
some form of timer, the operation being repeated if the timer event
triggers before the operation has completed.
Programming such systems requires manipulating many tens of thousands of timers in an eecient manner.
• Distributed — switching systems are inherently distributed, so our
system should structured in such a way that it is easy to go from a
single-node system to a multi-node distributed system.

2.2. PROBLEM DOMAIN

15

• Hardware interaction — Switching systems have large amounts of
peripheral hardware which must be controlled and monitored. This
implies that it should be possible to write eecient device drivers,
and that context switching between dicerent device drivers should
be eecient.
• Large sodware systems — switching systems are large, for example,
the Ericsson AXE10, and the AT&T 5ESS switch, have several million lines of program code [71]. This means that our sodware systems
must work with millions of lines of source code.
• Complex functionality — switching systems have complex functionality. Market pressure encourages the development, and deployment
of systems with large numbers of complex features. Oden systems
are deployed before the interaction between such features is well
understood. During the lifetime of a system the feature set will probably be changed and extended in many ways. Feature, and sodware
upgrade must be performed “in place,” that is, without stopping the
system.
• Continuous operation — telecommunications systems are designed
for many years of continuous operation. This implies that operations like sodware, and hardware maintenance, must be performed
without stopping the system.
• Quality requirements — switching systems should run with an acceptable level of service even in the presence of errors. Telephone
exchanges are expected to be extremely reliable.1
• Fault tolerance — switching systems should be “fault tolerant.” This
means that from the outset we know that faults will occur, and that
we must design a sodware and hardware infrastructure that can deal
with these faults, and provide an acceptable level of service even in
the presence of faults.
1

Typically having less than two hours of down-time in 40 years [48].

16

CHAPTER 2. THE ARCHITECTURAL MODEL

While these requirements came originally from the telecoms world they
are by no means exclusive to that particular problem domain. Many modern Internet services (for example, web servers) would have a strikingly
similar list of requirements.

2.3

Philosophy

How can we make a fault-tolerant sodware system which behaves in a
reasonable manner in the presence of sodware errors? Answering this will
take the rest of this thesis. I will start by giving a short answer which will
be refined in the remainder of the thesis.
To make a fault-tolerant sodware system which behaves reasonably in
the presence of sodware errors we proceed as follows:
1. We organise the sodware into a hierarchy of tasks that the system has
to perform. Each task corresponds to the achievement of a number
of goals. The sodware for a given task has to try and achieve the
goals associated with the task.
Tasks are ordered by complexity. The top level task is the most
complex, when all the goals in the top level task can be achieved
then the system should function perfectly. Lower level tasks should
still allow the system to function in an acceptable manner, though it
may ocer a reduced level of service.
The goals of a lower level task should be easier to achieve than the
goals of a higher level task in the system.
2. We try to perform the top level task.
3. If an error is detected when trying to achieve a goal, we make an
attempt to correct the error. If we cannot correct the error we immediately abort the current task and start performing a simpler task.
Programming a hierarchy of tasks needs a strong encapsulation method.
We need strong encapsulation for error isolation. We want to stop pro-

2.3. PHILOSOPHY

17

gramming errors in one part of the system adversely acecting sodware in
other parts of the system.
We need to isolate all the code that runs in order to achieve a goal in
such a way that we can detect if any errors occurred when trying to achieve
a goal. Also, when we are trying to simultaneously achieve multiple goals
we do not want a sodware error occurring in one part of the system to
propagate to another part of the system.
The essential problem that must be solved in making a fault-tolerant
sodware system is therefore that of fault-isolation. Dicerent programmers
will write dicerent modules, some modules will be correct, others will have
errors. We do not want the errors in one module to adversely acect the
behaviour of a module which does not have any errors.
To provide fault-isolation we use the traditional operating system notion of a process. Processes provide protection domains, so that an error in
one process cannot acect the operation of other processes. Dicerent programmers write dicerent applications which are run in dicerent processes;
errors in one application should not have a negative influence on the other
applications running in the system.
This is, of course, only true to a first approximation. Since all processes
use the same CPU, and memory, processes which try to hog the CPU or
which try to use excessive memory can negatively acect other processes in
the system. The extent to which processes can interfere with each other
depends upon the design characteristics of the operating system.
In our system processes, and concurrency, are part of the programming
language and are not provided by the host operating system. This has a
number of advantages over using operating system processes:
• Concurrent programs run identically on dicerent OSs—we are not
limited by how processes are implemented on any particular operating system. The only observable dicerence when moving between
OS’s, and processors should be due to dicerent CPU speeds and
memory sizes etc. All issues of synchronization, and inter-process
interaction should be the same irrespective of the properties of the
host operating system.

18

CHAPTER 2. THE ARCHITECTURAL MODEL
• Our language based processes are much lighter-weight than conventional OS processes. Creating a new process in our language is a
highly eecient operation, some orders of magnitude faster than process creation in most operating systems[12, 14], and orders of magnitude faster than thread creation in most programming languages.
• Our system has very little need of an operating system. We make
use of very few operating system services, thus it is relatively easy
to port our system to specialised environments such as embedded
systems.

Our applications are structured using large numbers of communicating
parallel processes. We take this approach because:
1. It provides an architectural infrastructure — we can organize our system as a set of communicating processes. By enumerating all the
processes in our system, and defining the message passing channels
between the processes we can conveniently partition the system into
a number of well-defined sub-components which can be independently implemented, and tested. This is the methodology implied
by the top level of the SDL [45] system design methodology.
2. Potential eeciency — a system which is designed to be implemented
as a number of independent concurrent processes can be implemented on a multi-processor or run on a distributed network of
processors. Note that the eeciency is only potential, and works best
when the application can be partitioned into a number of truly independent tasks. If there are strong data dependencies between the
tasks this might not always be possible.
3. Fault isolation — concurrent processes with no data sharing provide
a strong measure of fault isolation. A sodware error in a concurrent
process should not influence processing in the other processes in the
system.

2.4. CONCURRENCY ORIENTED PROGRAMMING

19

Of these three uses of concurrency, the first two are non-essential characteristics and can be provided by some kind of in-built scheduler which
provides various forms of pseudo-parallel time sharing between processes.
The third characteristic is essential for programming fault-tolerant systems. Each independent activity should be performed in a completely
isolated process. Such processes should share no data, and only communicate by message passing. This is to limit the consequences of a sodware
error.
As soon as two processes share any common resource, for example,
memory or a pointer to memory, or a mutex etc the possibility exists that
a sodware error in one of the processes will corrupt the shared resource.
Since eliminating all such sodware errors for large sodware systems is an
unsolved problem I think that the only realistic way to build large reliable
systems is by partitioning the system into independent parallel processes,
and by providing mechanisms for monitoring and restarting these processes.

2.4

Concurrency oriented programming

In our system concurrency plays a central role, so much so that I have
coined the term Concurrency Oriented Programming to distinguish this style
of programming from other programming styles.2
In Concurrency Oriented Programming the concurrent structure of
the program should follow the concurrent structure of the application. It
is particularly suited to programming applications which model or interact
with the real world.
Concurrency Oriented Programming also provides the two major advantages commonly associated with object-oriented programming. These
are polymorphism and the use of defined protocols having the same message passing interface between instances of dicerent process types.
When we partition a problem into a number of concurrent processes
we can arrange that all the processes respond to the same messages (ie
2
Such as Object Oriented programming which models the world in terms of Objects, Functional Programming which uses functions, or Logic Programming with uses relations.

20

CHAPTER 2. THE ARCHITECTURAL MODEL

they are polymorphic,) and that they all follow the same message passing
interface.
The word concurrency refers to sets of events which happen simultaneously. The real world is concurrent, and consists of a large number
of events many of which happen simultaneously. At an atomic level our
bodies are made up of atoms, and molecules, in simultaneous motion.
At a macroscopic level the universe is populated with galaxies of stars in
simultaneous motion.
When we perform a simple action, like driving a car along a freeway,
we are aware of the fact that there may be several hundreds of cars within
our immediate environment, yet we are able to perform the complex task
of driving a car, and avoiding all these potential hazards without even
thinking about it.
In the real world sequential activities are a rarity. As we walk down the
street we would be very surprised to find only one thing happening, we
expect to encounter many simultaneous events.
If we did not have the ability to analyze and predict the outcome of
many simultaneous events we would live in great danger, and tasks like
driving a car would be impossible. The fact that we can do things which
require processing massive amounts of parallel information suggests that
we are equipped with perceptual mechanisms which allow us to intuitively
understand concurrency without consciously thinking about it.
When it comes to computer programming things suddenly become
inverted. Programming a sequential chain of activities is viewed the norm
, and in some sense is thought of as being easy, whereas programming
collections of concurrent activities is avoided as much as possible, and is
generally perceived as being diecult.
I believe that this is due to the poor support which is provided for concurrency in virtually all conventional programming languages. The vast
majority of programming languages are essentially sequential; any concurrency in the language is provided by the underlying operating system, and
not by the programming language.
In this thesis I present a view of the world where concurrency is provided by the programming language, and not by the underlying operating
system. Languages which have good support for concurrency I call Concur-

2.4. CONCURRENCY ORIENTED PROGRAMMING

21

rency Oriented Languages, or COPLs for short.

2.4.1

Programming by observing the real world

We oden want to write programs that model the world or interact with the
world. Writing such a program in a COPL is easy. Firstly, we perform an
analysis which is a three-step process:
1. We identify all the truly concurrent activities in our real world activity.
2. We identify all message channels between the concurrent activities.
3. We write down all the messages which can flow on the dicerent
message channels.
Now we write the program. The structure of the program should
exactly follow the structure of the problem. Each real world concurrent
activity should be mapped onto exactly one concurrent process in our
programming language. If there is a 1:1 mapping of the problem onto the
program we say that the program is isomorphic to the problem.
It is extremely important that the mapping is exactly 1:1. The reason
for this is that it minimizes the conceptual gap between the problem and
the solution. If this mapping is not 1:1 the program will quickly degenerate,
and become diecult to understand. This degeneration is oden observed
when non-CO languages are used to solve concurrent problems. Oden
the only way to get the program to work is to force several independent
activities to be controlled by the same language thread or process. This
leads to a inevitable loss of clarity, and makes the programs subject to
complex and irreproducible interference errors.
In performing our analysis of the problem we must choose an appropriate granularity for our model. For example, if we were writing an instant
messaging system, we might choose to use one process per user and not
one process for every atom in the user’s body.

22

CHAPTER 2. THE ARCHITECTURAL MODEL

2.4.2

Characteristics of a COPL

COPLs are characterised by the following six properties:
1. COPLs must support processes. A process can be thought of as a
self-contained virtual machine.
2. Several processes operating on the same machine must be strongly
isolated. A fault in one processe should not adversely ecect another
process, unless such interaction is explicitly programmed.
3. Each process must be identified by a unique unforgeable identifier.
We will call this the Pid of the process.
4. There should be no shared state between processes. Processes interact by sending messages. If you know the Pid of a process then you
can send a message to the process.
5. Message passing is assumed to be unreliable with no guarantee of
delivery.
6. It should be possible for one process to detect failure in another
process. We should also know the reason for failure.
Note that COPLs must provide true concurrency, thus objects represented as processes are truly concurrent, and messages between processes
are true asynchronous messages, unlike the disguised remote procedure
calls found in many object-oriented languages.
Note also that the reason for failure may not always be correct. For
example, in a distributed system, we might receive a message informing
us that a process has died, when in fact a network error has occurred.

2.4.3 Process isolation
The notion of isolation is central to understanding COP, and to the construction of fault-tolerant sodware. Two processes operating on the same

2.4. CONCURRENCY ORIENTED PROGRAMMING

23

machine must be as independent as if they ran on physically separated
machines.
Indeed the ideal architecture to run a CO program on would be a
machine which assigned one new physical processor per sodware process.
Until this ideal is reached we will have to live with the fact that multiple
processes will run on the same machine. We should still think of them as
if they ran on physically separated machine.
Isolation has several consequences:
1. Processes have “share nothing” semantics. This is obvious since they
are imagined to run on physically separated machines.
2. Message passing is the only way to pass data between processes.
Again since nothing is shared this is the only means possible to
exchange data.
3. Isolation implies that message passing is asynchronous. If process
communication is synchronous then a sodware error in the receiver
of a message could indefinitely block the sender of the message
destroying the property of isolation.
4. Since nothing is shared, everything necessary to perform a distributed computation must be copied. Since nothing is shared, and
the only way to communicate between processes is by message passing, then we will never know if our messages arrive (remember we
said that message passing is inherently unreliable.) The only way to
know if a message has been correctly sent is to send a confirmation
message back.
Programming a system of processes subject to the above rules may
appear at first sight to be diecult—ader all most concurrency extensions to
sequential programming languages provide facilities for almost exactly the
opposite providing things like locks, and semaphores, and provision for
shared data, and reliable message passing. Fortunately, the opposite turns
out to be true—programming such a system turns out to be surprisingly

24

CHAPTER 2. THE ARCHITECTURAL MODEL

easy, and the programs you write can be made scalable, and fault-tolerant,
with very little ecort.
Because all our processes are required to be complete isolated adding
more processes cannot acect the original system. The sodware must have
been written so as to handle collections of isolated processes, so adding a
few more processors is usually accomplished without any major changes
to the application sodware.
Since we made no assumptions about reliable message passing, and
must write our application so that it works in the presence of unreliable
message passing it should indeed work in the presence of message passing
errors. The initial ecort involved will reward us when we try to scale up
our systems.

2.4.4

Names of processes

We require that the names of processes are unforgeable. This means that it
should be impossible to guess the name of a process, and thereby interact
with that process. We will assume that processes know their own names,
and that processes which create other processes know the names of the
processes which they have created. In other words, a parent process knows
the names of its children.
In order to write COPLs we will need mechanisms for finding out the
names of the processes involved. Remember, if we know the name of a
process, we can send a message to that process.
System security is intimately connected with the idea of knowing the
name of a process. If we do not know the name of a process we cannot
interact with it in any way, thus the system is secure. Once the names of
processes become widely know the system becomes less secure. We call
the process of revealing names to other processes in a controlled manner
the name distribution problem— the key to security lies in the name distribution problem. When we reveal a Pid to another process we will say that
we have published the name of the process. If a name is never published
there are no security problems.
Thus knowing the name of a process is the key element of security.
Since names are unforgeable the system is secure only if we can limit the

2.4. CONCURRENCY ORIENTED PROGRAMMING

25

knowledge of the names of the processes to trusted processes.
In many primitive religions it was believed that humans had powers
over spirits if they could command them by their real names. Knowing
the real name of a spirit gave you power over the spirit, and using this
name you could command the spirit to do various things for you. COPLs
use the same idea.

2.4.5

Message passing

Message passing obeys the following rules:
1. Message passing is assumed to be atomic which means that a message is either delivered in its entirety or not at all.
2. Message passing between a pair of processes is assumed to be ordered meaning that if a sequence of messages is sent and received
between any pair of processes then the messages will be received in
the same order they were sent.
3. Messages should not contain pointers to data structures contained
within processes—they should only contain constants and/or Pids.
Note that point two is a design decision, and does not reflect any underlying semantics in the network used to transmit messages. The underlying
network might reorder the messages, but between any pair of processes
these messages can be bucered, and re-assembled into the correct order
before delivery. This assumption makes programming message passing
applications much easier than if we had to always allow for out of order
messages.
We say that such message passing has send and pray semantics. We
send the message and pray that it arrives. Confirmation that a message has
arrived can be achieved by returning a confirmation message (sometimes
called round-trip confirmation.) Interestingly many programmers only believe in round-trip confirmation, and use it even if the underlying transport
layers are supposed to provide reliable data transport, and even if such
checks are supposedly irrelevant.

26

CHAPTER 2. THE ARCHITECTURAL MODEL

Message passing is also used for synchronisation. Suppose we wish to
synchronise two processes A, and B. If A sends a message to B then B
can only receive this message at some point in time ader A has sent the
message. This is known as casual ordering in distributed systems theory.
In COPLs all interprocess synchronisation is based on this simple idea.

2.4.6

Protocols

Isolation of components, and message passing between components, is
architecturally suecient for protecting a system from the consequences of
a sodware error, but it is not suecient to specify the behaviour of a system,
nor, in the event of some kind of failure to determine which component
has failed.
Up to now we have assumed that failure is a property of a single
component, a single component will either do what it is supposed to do or
fail as soon as possible. It might happen, however, that no components are
observed to fail, and yet the system still does not work as expected.
To complete our programming model, we add therefore one more
thing. Not only do we need completely isolated components that communicate only by message passing, but also we need to specify the communication protocols that are used between each pair of components that
communicate with each other.
By specifying the communication protocol that should be obeyed between two components we can easily find out if either of the components
involved has violated the protocol. Guaranteeing that the protocol is enforced should be done by static analysis, if possible, or failing this by
compiling run-time checks into the code.

2.4.7

COP and programmer teams

Building a large system involves the work of many programmers, sometimes many hundreds of programmers are involved. To organise their
work these programmers are organised into smaller groups or teams. Each
group is responsible for one or more logical component in the system. On
a day-to-day basis, the groups communicate by message-passing (e-mail

2.5. SYSTEM REQUIREMENTS

27

or phone) but do not regularly meet. In some cases the groups work in
dicerent countries, and never meet. It is amusing to note that not only
is the organisation of a sodware system into isolated components which
communicate by pure message passing desirable for a number of reasons,
but also that it is the way that large programming groups are organised.

2.5

System requirements

To support a CO style of programming, and to make a system that can
satisfy the requirements of a telecoms system we arrive at a set of requirements for the essential characteristics of a system. These requirements are
for the system as a whole—here I am not interested in whether these requirements are satisfied in a programming language or in the libraries, and
construction methods, which accompany the language.
There are six essential requirements on the underlying operating system, and programming languages.
R1. Concurrency — Our system must support concurrency. The
computational ecort needed to create or destroy a concurrent
process should be very small, and there should be no penalty
for creating large numbers of concurrent processes.
R2. Error encapsulation — Errors occurring in one process must
not be able to damage other processes in the system.
R3. Fault detection — It must be possible to detect exceptions both
locally (in the processes where the exception occurred,) and
remotely (we should be able to detect that an exception has
occurred in a non-local process).
R4. Fault identification — We should be able to identify why an
exception occurred.
R5. Code upgrade — there should exist mechanisms to change
code as it is executing, and without stopping the system.

28

CHAPTER 2. THE ARCHITECTURAL MODEL

R6. Stable storage — we need to store data in a manner which
survives a system crash.
It is also important that systems satisfying the above requirements are
eeciently implemented—concurrency is not much use if we cannot reliably
create many tens of thousands of processes. Fault identification is not much
use if it does not contain enough information to allow us to correct the
error at a later date.
Satisfying the above requirements can be done in a number of different ways. Concurrency, for example, can be provided as a language
primitive (as, for example, in Erlang), or in the operating system (for example, Unix). Languages like C or Java which are not concurrent can
make use of operating system primitives which gives the user the illusion
that they are concurrent; indeed concurrent programs can be written in
languages which are not themselves concurrent.

2.6

Language requirements

The programming language which we use to program the system must
have:
• Encapsulation primitives — there must be a number of mechanisms
for limiting the consequences of an error. It should be possible to
isolate processes so that they cannot damage each other.
• Concurrency — the language must support a lightweight mechanism
to create parallel process, and to send messages between the processes. Context switching between process, and message passing,
should be eecient. Concurrent processes must also time-share the
CPU in some reasonable manner, so that CPU bound processes do
not monopolise the CPU, and prevent progress of other processes
which are “ready to run.”
• Fault detection primitives — which allow one process to observe another process, and to detect if the observed process has terminated
for any reason.

2.7. LIBRARY REQUIREMENTS

29

• Location transparency — If we know the Pid of a process then we
should be able to send a message to the process.
• Dynamic code upgrade — It should be possible to dynamically
change code in a running system. Note that since many processes
will be running the same code, we need a mechanism to allow existing processes to run “old” code, and for “new” processes to run the
modified code at the same time.
Not only should the language satisfy these requirements, but it should
also satisfy them in a reasonably eecient manner. When we program we
do not want to limit our freedom of expression by “counting processes” etc,
nor do we want to worry about what will happen if a process inadvertently
tries to monopolise the CPU.
The maximum number of processes in the system should be sueciently
large that for programming purposes we do not have to consider this maximum number a limiting factor. We might need, for example, to create of
the order of one hundred thousand processes in order to make a switching
system which maintains ten thousand simultaneous user sessions.3
This mix of features is needed to simplify applications programming.
Mapping the semantics of a distributed set of communicating components
onto an Erlang program is greatly simplified if we can map the concurrent
structure of the problem in a 1:1 manner onto the process structure of the
application program which solves the problem.

2.7

Library requirements

Language is not everything—a number of things are provided in the accompanying system libraries. The essential set of libraries routines must
provide:
• Stable storage — this is storage which survives a crash.
3

Assuming 10 processes per session.

30

CHAPTER 2. THE ARCHITECTURAL MODEL
• Device drivers — these must provide a mechanism for communication with the outside world.
• Code upgrade — this allows us to upgrade code in a running system.
• Infrastructure — for starting, and stopping the system, logging errors
etc.

Observe that our library routines, which are mostly written in Erlang,
provide most of the services which are conventionally provided by an
operating system.
Since Erlang process are isolated from each other, and communicate
only by message passing, they behave very much like operating system
processes which communicate through pipes or sockets.
Many of the features which are conventionally provided by an operating system have moved from the operating system into the programming
language. The remaining operating system only provides a primitive set of
device drivers.

2.8 Application libraries
Stable storage etc is not provided as a language primitive in Erlang, but
is provided in the basic Erlang libraries. Having such libraries is a precondition for writing any complex application sodware. Complex applications need much higher-level abstractions than storage etc. To build such
applications we need pre-packaged sodware entities to help us program
things like client-server solutions etc.
The OTP libraries provide us with a complete set of design patterns
(called behaviours) for building fault-tolerant applications. In this thesis I
will talk about a minimal set of behaviours, which can be used for building
fault-tolerant applications. These are:
• supervisor — a supervision model.
• gen_server — a behaviour for implementing client-server applications.

2.9. CONSTRUCTION GUIDELINES

31

• gen_event — a behaviour used for implementing event handling
sodware.
• gen_fsm — a behaviour used for implementing finite state machines.
Of these, the central component that is used for programming faulttolerant applications is the supervision model.

2.9

Construction guidelines

In addition to explaining a general philosophy of programming faulttolerant applications, we need more specific guidelines that apply to the
programming languages that we wish to use to program our applications.
We also need example programs, and examples of how to use the library
routines.
The open source Erlang release contains such guidelines which have
been used as the basis for systems with millions of lines of Erlang code.
Appendix B reproduces the programming guidelines, which can be found
in the Erlang open source release. This thesis contains additional guidelines, which are organized as follows:
• The overall philosophy of our architecture is described in this chapter.
• The notion of an error is discussed in several places. Sections 5.3,
and 4.3 describe what is meant by an error; section 4.4 gives advice
on the correct programing style to use when programming for errors
in Erlang.
• Examples of how to program simple components can be found in
Chapter 4, and examples of how to use the OTP behaviours in
chapter 6.

32

CHAPTER 2. THE ARCHITECTURAL MODEL

2.10

Related work

The inability to isolate sodware components from each other is the main
reason why many popular programming languages cannot be used for
making robust system sodware.
It is essential for security to be able to isolate mistrusting programs from one another, and to protect the host platform from
such programs. Isolation is diecult in object-oriented systems
because objects can easily become aliased.4 —Bryce [21]
Bryce goes on to say that object aliasing is diecult if not impossible to
detect in practice, and recommends the use of protection domains (akin to
OS processes) to solve this problem.
In a paper on Java Czajkowski, and Daynès, from Sun Microsystems,
write:
The only safe way to execute multiple applications, written
in the Java programming language, on the same computer
is to use a separate JVM for each of them, and to execute
each JVM in a separate OS process. This introduces various
ineeciencies in resource utilization, which downgrades performance, scalability, and application startup time. The benefits
the language can ocer are thus reduced mainly to portability
and improved programmer productivity. Granted these are
important, but the full potential of language-provided safety is
not realized. Instead there exists a curious distinction between
“language safety,” and “real safety”. — [28]
In this paper they introduce the MVM (an extension to the JVM) where
their goal is:
... to turn the JVM into an execution environment akin to
an OS. In particular, the abstraction of a process, ocered by
4

An aliased object is one where at least two other objects hold a reference to it.

2.10. RELATED WORK

33

modern OSes, is the role model in terms of features; isolation
from other computations, resources accountability and control,
and ease of termination and resource reclamation.
To achieve this they conclude that:
... tasks cannot directly share objects, and that the only way
for tasks to communicate is to use standard, copying communication mechanisms, ...
These conclusions are not new. Very similar conclusions were arrived
at some two decades earlier by Jim Gray who described the architecture
of the Tandem Computer in his highly readable paper Why do computers
stop and what can be done about it. He says:
As with hardware, the key to sodware fault-tolerance is to hierarchically decompose large systems into modules, each module being a unit of service and a unit of failure. A failure of a
module does not propagate beyond the module.
...
The process achieves fault containment by sharing no state
with other processes; its only contact with other processes is
via messages carried by a kernel message system. — [38]
Language which support this style of programming (parallel processes,
no shared data, pure message passing) are what Andrews and Schneider
[4] refer to as a “Message oriented languages.” The language with the
delightful name PLITS5 (1978) [35] is probably the first example of such a
programming language:
The fundamental design decision in the implementation of
RIG6 was to allow a strict message discipline with no shared
5
6

Programming language in the sky.
RIG was a small system written in PLITS.

34

CHAPTER 2. THE ARCHITECTURAL MODEL
data structures. All communication between user and server
messages is through messages which are routed by the Aleph
kernel. This message discipline has proved to be very flexible
and reliable. — [35]

Turning away from language for a while, we ask what properties should
an individual process have?
Schneider [60, 59] answered this question by giving three properties
that he thought a hardware system should have in order to be suitable for
programming a fault-tolerant system. These properties Schneider called:
1. Halt on failure — in the event of an error a processor should halt
instead of performing a possibly erroneous operation.
2. Failure status property — when a processor fails, other processors
in the system must be informed. The reason for failure must be
communicated.
3. Stable Storage Property — the storage of a processor should be partitioned into stable storage (which survives a processor crash,) and
volatile storage which is lost if a processor crashes.
A processor having these properties Schneider called a fail-stop processor. The idea is that if a failure7 occurs it is pointless to continue. The
process should halt instead of continuing and possibly causing more damage. In a fault-stop processor, state is stored in either volatile or stable
memory. When the processor crashes all data in volatile memory is lost,
but all state that was stored in stable storage should be available ader the
crash.
A remarkably similar idea can be found in [38] where Gray talks about
“fail-fast” processes.
The process approach to fault isolation advocates that the process sodware be fail-fast, it should either function correctly or
it should detect the fault, signal failure and stop operating.
7

Here Schneider considers a failure as an error which cannot be corrected.

2.10. RELATED WORK

35

Processes are made fail-fast by defensive programming. They
check all their inputs, intermediate results and data structures
as a matter of course. If any error is detected, they signal
a failure and stop. In the terminology of [Cristian], fail-fast
sodware has small fault detection latency. — [38]
Both Schneider, and Gray, have the same essential idea; one is talking
about hardware, the other about sodware but the underlying principles are
the same.
Renzel argued that it is important that processes fail as soon as possible
ader an uncorrectable error has occurred:
A fault in a sodware system can cause one or more errors.
The latency time which is the interval between the existence
of the fault and the occurrence of the error can be very high,
which complicates the backwards analysis of an error ...
For an ecective error handling we must detect errors and failures as early as possible — [58]
Bearing in mind these arguments, and our original requirements I advocate a system with the following properties:
1. Processes are the units of error encapsulation — errors occurring in
a process will not acect other processes in the system. We call this
property strong isolation.
2. Processes do what they are supposed to do or fail as soon as possible.
3. Failure, and the reason for failure, can be detected by remote processes.
4. Processes share no state, but communicate by message passing.
A language and system with such properties, has the necessary preconditions for writing fault-tolerant sodware. Later in this thesis we will see
how these properties are satisfied by Erlang, and the Erlang libraries.

36

CHAPTER 2. THE ARCHITECTURAL MODEL

Many of the ideas in this thesis are not new—the fundamental principles
for making a fault-tolerant system are described in Gray’s [38] paper.
Many of the features of the Tandem computer bear a striking similarity to the design principles in the OTP system, and to the fundamental
principles of Concurrency Oriented Programming which where discussed
earlier.
Here are two quotes from the paper, firstly the design principles on
page 15 of [38].
The keys to this sodware fault-tolerance are:
• Sodware modularity through processes, and messages.
• Fault containment through fail-fast sodware modules.
• Process-pairs to tolerant hardware, and transient sodware
faults.
• Transaction mechanisms to provide data, and message
integrity.
• Transaction mechanisms combined with process-pairs to
ease exception handling, and tolerate sodware faults.
Sodware modularity through processes and messages. As with
hardware, the key to sodware fault-tolerance is to hierarchically decompose large systems into modules, each module being a unit of service and a unit of failure. A failure of a module
does not propagate beyond the module.
There is considerable controversy about how to modularize
sodware. Starting with Burroughs’ Espol and continuing through
languages like Mesa and Ada, compiler writers have assumed
perfect hardware and contended that they can provide good
isolation through static compile-time type checking. In contrast, operating systems designers have advocated run-time
checking combined with the process as the unit of protection
and failure.

2.10. RELATED WORK

37

Although compiler checking and exception handling provided
by programming languages are real assets, history seems to
have favored the run-time checks plus the process approach to
fault-containment. It has the virtue of simplicity—if a process or
its processor misbehaves, stop it. The process provides a clean
unit of modularity, service, fault containment and failure.
Fault containment through fail-fast sodware modules.
The process achieves fault containment by sharing no state
with other processes; its only contact with other processes is
via messages carried by a kernel message system. — [38]
If we compare this to our current Erlang system we see many striking
similarities. There are certain dicerence—in Erlang “defensive programming” is not recommended since the compiler adds the necessary checks
to make this style of programming unnecessary. Gray’s “transaction mechanism” is provides by the mnesia data base.8 The containment and processing of errors is managed by the “supervision tree” behaviours in the
OTP libraries.
The idea of “fail-fast” modules is mirrored in our guidelines for programming where we say that processes should only do when they are supposed to do according to the specification, otherwise they should crash.
The supervision hierarchies in our system correspond to the hierarchies of
modules that Gray refers to. This idea can also be found in the work of
Candea and Fox [22] who talked about “crash-only sodware”—they argue
that allowing components to crash and then restart leads to a simpler fault
model and more reliable code.
More modern work with object-oriented systems has also recognised
the importance of isolating sodware components from each other. In [21]
Bryce and Razafimahefa argue that is is essential to isolate programs from
one another, and from the programs which run in the host operating system. This, they consider, is the essential characteristic that any object
system must have. As they point out in their paper, this is a diecult
problem in an object-oriented context.
8

Written in Erlang.

38
